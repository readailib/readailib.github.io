<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content>
    <meta name="keyword" content>
    <link rel="shortcut icon" href="/images/favicon.png">
    <!-- Place this tag in your head or just before your close body tag. -->
    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <title>
        
          Kubernetes v1.10.x HA 全手動苦工安裝教學(TL;DR) - ShenHengheng&#39;s Blog
        
    </title>

    <link rel="canonical" href="https://readailib.github.io/2018/04/05/kubernetes/deploy/manual-v1.10/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/beantech.min.css">

    <!-- Pygments Highlight CSS -->
    <link rel="stylesheet" href="/css/highlight.css">

    <link rel="stylesheet" href="/css/widget.css">

    <link rel="stylesheet" href="/css/rocket.css">

    <link rel="stylesheet" href="/css/signature.css">

    <link rel="stylesheet" href="/css/toc.css">

    <!-- Custom Fonts -->
    <!-- <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="https://cdn.staticfile.org/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">
	<!-- Modified by Yu-Hsuan Yen -->
<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        
            background-image: url('/images/kube/bg.png')
            /*post*/
        
    }
    
</style>

<header class="intro-header">
    <!-- Signature -->
    <div id="signature">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                
                    <div class="post-heading">
                        <div class="tags">
                            
                              <a class="tag" href="/tags/#Docker" title="Docker">Docker</a>
                            
                              <a class="tag" href="/tags/#Kubernetes" title="Kubernetes">Kubernetes</a>
                            
                              <a class="tag" href="/tags/#Calico" title="Calico">Calico</a>
                            
                        </div>
                        <h1>Kubernetes v1.10.x HA 全手動苦工安裝教學(TL;DR)</h1>
                        <h2 class="subheading"></h2>
                        <span class="meta">
                            Posted by ShenHengheng on
                            2018-04-05
                        </span>
                    </div>
                


                </div>
            </div>
        </div>
    </div>
</header>


    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">ShenH.&#39;s Blog</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                        <li>
                            <a href="/archive/">Archives</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/about/">About Me</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/tags/">tags</a>
                        </li>
                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                        
                    

                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    <!-- Modify by Yu-Hsuan Yen -->

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <p>本篇延續過往<code>手動安裝方式</code>來部署 Kubernetes v1.10.x 版本的 High Availability 叢集，主要目的是學習 Kubernetes 安裝的一些元件關析與流程。若不想這麼累的話，可以參考 <a href="https://kubernetes.io/docs/getting-started-guides/" target="_blank" rel="noopener">Picking the Right Solution</a> 來選擇自己最喜歡的方式。</p>
<p>本次安裝的軟體版本：</p>
<ul>
<li>Kubernetes v1.10.0</li>
<li>CNI v0.6.0</li>
<li>Etcd v3.1.13</li>
<li>Calico v3.0.4</li>
<li>Docker CE latest version</li>
</ul>
<a id="more"></a>
<p><img src="/images/kube/kubernetes-aa-ha.png" alt></p>
<h2 id="節點資訊"><a href="#節點資訊" class="headerlink" title="節點資訊"></a>節點資訊</h2><p>本教學將以下列節點數與規格來進行部署 Kubernetes 叢集，作業系統可採用<code>Ubuntu 16.x</code>與<code>CentOS 7.x</code>：</p>
<table>
<thead>
<tr>
<th>IP Address</th>
<th>Hostname</th>
<th>CPU</th>
<th>Memory</th>
</tr>
</thead>
<tbody>
<tr>
<td>192.16.35.11</td>
<td>k8s-m1</td>
<td>1</td>
<td>4G</td>
</tr>
<tr>
<td>192.16.35.12</td>
<td>k8s-m2</td>
<td>1</td>
<td>4G</td>
</tr>
<tr>
<td>192.16.35.13</td>
<td>k8s-m3</td>
<td>1</td>
<td>4G</td>
</tr>
<tr>
<td>192.16.35.14</td>
<td>k8s-n1</td>
<td>1</td>
<td>4G</td>
</tr>
<tr>
<td>192.16.35.15</td>
<td>k8s-n2</td>
<td>1</td>
<td>4G</td>
</tr>
<tr>
<td>192.16.35.16</td>
<td>k8s-n2</td>
<td>1</td>
<td>4G</td>
</tr>
</tbody>
</table>
<p>另外由所有 master 節點提供一組 VIP <code>192.16.35.10</code>。</p>
<blockquote>
<ul>
<li>這邊<code>m</code>為 K8s Master 節點，<code>n</code>為 K8s Node 節點。</li>
<li>所有操作全部用<code>root</code>使用者進行(方便用)，以 SRE 來說不推薦。</li>
<li>可以下載 <a href="https://kairen.github.io/files/manual-v1.10/Vagrantfile" target="_blank" rel="noopener">Vagrantfile</a> 來建立 Virtualbox 虛擬機叢集。不過需要注意機器資源是否足夠。</li>
</ul>
</blockquote>
<h2 id="事前準備"><a href="#事前準備" class="headerlink" title="事前準備"></a>事前準備</h2><p>開始安裝前需要確保以下條件已達成：</p>
<ul>
<li><code>所有節點</code>彼此網路互通，並且<code>k8s-m1</code> SSH 登入其他節點為 passwdless。</li>
<li>所有防火牆與 SELinux 已關閉。如 CentOS：</li>
</ul>
<pre><code class="sh">$ systemctl stop firewalld &amp;&amp; systemctl disable firewalld
$ setenforce 0
$ vim /etc/selinux/config
SELINUX=disabled
</code></pre>
<ul>
<li><code>所有節點</code>需要設定<code>/etc/hosts</code>解析到所有叢集主機。</li>
</ul>
<pre><code>...
192.16.35.11 k8s-m1
192.16.35.12 k8s-m2
192.16.35.13 k8s-m3
192.16.35.14 k8s-n1
192.16.35.15 k8s-n2
192.16.35.16 k8s-n3
</code></pre><ul>
<li><code>所有節點</code>需要安裝 Docker CE 版本的容器引擎：</li>
</ul>
<pre><code class="sh">$ curl -fsSL &quot;https://get.docker.com/&quot; | sh
</code></pre>
<blockquote>
<p>不管是在 <code>Ubuntu</code> 或 <code>CentOS</code> 都只需要執行該指令就會自動安裝最新版 Docker。<br>CentOS 安裝完成後，需要再執行以下指令：</p>
<pre><code class="sh">$ systemctl enable docker &amp;&amp; systemctl start docker
</code></pre>
</blockquote>
<ul>
<li><code>所有節點</code>需要設定<code>/etc/sysctl.d/k8s.conf</code>的系統參數。</li>
</ul>
<pre><code class="sh">$ cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

$ sysctl -p /etc/sysctl.d/k8s.conf
</code></pre>
<ul>
<li>Kubernetes v1.8+ 要求關閉系統 Swap，若不關閉則需要修改 kubelet 設定參數，在<code>所有節點</code>利用以下指令關閉：</li>
</ul>
<pre><code class="sh">$ swapoff -a &amp;&amp; sysctl -w vm.swappiness=0
</code></pre>
<blockquote>
<p>記得<code>/etc/fstab</code>也要註解掉<code>SWAP</code>掛載。</p>
</blockquote>
<ul>
<li>在<code>所有節點</code>下載 Kubernetes 二進制執行檔：</li>
</ul>
<pre><code class="sh">$ export KUBE_URL=&quot;https://storage.googleapis.com/kubernetes-release/release/v1.10.0/bin/linux/amd64&quot;
$ wget &quot;${KUBE_URL}/kubelet&quot; -O /usr/local/bin/kubelet
$ chmod +x /usr/local/bin/kubelet

# node 請忽略下載 kubectl
$ wget &quot;${KUBE_URL}/kubectl&quot; -O /usr/local/bin/kubectl
$ chmod +x /usr/local/bin/kubectl
</code></pre>
<ul>
<li>在<code>所有節點</code>下載 Kubernetes CNI 二進制檔案：</li>
</ul>
<pre><code class="sh">$ mkdir -p /opt/cni/bin &amp;&amp; cd /opt/cni/bin
$ export CNI_URL=&quot;https://github.com/containernetworking/plugins/releases/download&quot;
$ wget -qO- --show-progress &quot;${CNI_URL}/v0.6.0/cni-plugins-amd64-v0.6.0.tgz&quot; | tar -zx
</code></pre>
<ul>
<li>在<code>k8s-m1</code>需要安裝<code>CFSSL</code>工具，這將會用來建立 TLS Certificates。</li>
</ul>
<pre><code class="sh">$ export CFSSL_URL=&quot;https://pkg.cfssl.org/R1.2&quot;
$ wget &quot;${CFSSL_URL}/cfssl_linux-amd64&quot; -O /usr/local/bin/cfssl
$ wget &quot;${CFSSL_URL}/cfssljson_linux-amd64&quot; -O /usr/local/bin/cfssljson
$ chmod +x /usr/local/bin/cfssl /usr/local/bin/cfssljson
</code></pre>
<h2 id="建立叢集-CA-keys-與-Certificates"><a href="#建立叢集-CA-keys-與-Certificates" class="headerlink" title="建立叢集 CA keys 與 Certificates"></a>建立叢集 CA keys 與 Certificates</h2><p>在這個部分，將需要產生多個元件的 Certificates，這包含 Etcd、Kubernetes 元件等，並且每個叢集都會有一個根數位憑證認證機構(Root Certificate Authority)被用在認證 API Server 與 Kubelet 端的憑證。</p>
<blockquote>
<p>P.S. 這邊要注意 CA JSON 檔的<code>CN(Common Name)</code>與<code>O(Organization)</code>等內容是會影響 Kubernetes 元件認證的。</p>
</blockquote>
<h3 id="Etcd"><a href="#Etcd" class="headerlink" title="Etcd"></a>Etcd</h3><p>首先在<code>k8s-m1</code>建立<code>/etc/etcd/ssl</code>資料夾，然後進入目錄完成以下操作。</p>
<pre><code class="sh">$ mkdir -p /etc/etcd/ssl &amp;&amp; cd /etc/etcd/ssl
$ export PKI_URL=&quot;https://kairen.github.io/files/manual-v1.10/pki&quot;
</code></pre>
<p>下載<code>ca-config.json</code>與<code>etcd-ca-csr.json</code>檔案，並從 CSR json 產生 CA keys 與 Certificate：</p>
<pre><code class="sh">$ wget &quot;${PKI_URL}/ca-config.json&quot; &quot;${PKI_URL}/etcd-ca-csr.json&quot;
$ cfssl gencert -initca etcd-ca-csr.json | cfssljson -bare etcd-ca
</code></pre>
<p>下載<code>etcd-csr.json</code>檔案，並產生 Etcd 證書：</p>
<pre><code class="sh">$ wget &quot;${PKI_URL}/etcd-csr.json&quot;
$ cfssl gencert \
  -ca=etcd-ca.pem \
  -ca-key=etcd-ca-key.pem \
  -config=ca-config.json \
  -hostname=127.0.0.1,192.16.35.11,192.16.35.12,192.16.35.13 \
  -profile=kubernetes \
  etcd-csr.json | cfssljson -bare etcd
</code></pre>
<blockquote>
<p><code>-hostname</code>需修改成所有 masters 節點。</p>
</blockquote>
<p>完成後刪除不必要檔案：</p>
<pre><code class="sh">$ rm -rf *.json *.csr
</code></pre>
<p>確認<code>/etc/etcd/ssl</code>有以下檔案：</p>
<pre><code class="sh">$ ls /etc/etcd/ssl
etcd-ca-key.pem  etcd-ca.pem  etcd-key.pem  etcd.pem
</code></pre>
<p>複製相關檔案至其他 Etcd 節點，這邊為所有<code>master</code>節點：</p>
<pre><code class="sh">$ for NODE in k8s-m2 k8s-m3; do
    echo &quot;--- $NODE ---&quot;
    ssh ${NODE} &quot;mkdir -p /etc/etcd/ssl&quot;
    for FILE in etcd-ca-key.pem  etcd-ca.pem  etcd-key.pem  etcd.pem; do
      scp /etc/etcd/ssl/${FILE} ${NODE}:/etc/etcd/ssl/${FILE}
    done
  done
</code></pre>
<h3 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a>Kubernetes</h3><p>在<code>k8s-m1</code>建立<code>pki</code>資料夾，然後進入目錄完成以下章節操作。</p>
<pre><code class="sh">$ mkdir -p /etc/kubernetes/pki &amp;&amp; cd /etc/kubernetes/pki
$ export PKI_URL=&quot;https://kairen.github.io/files/manual-v1.10/pki&quot;
$ export KUBE_APISERVER=&quot;https://192.16.35.10:6443&quot;
</code></pre>
<p>下載<code>ca-config.json</code>與<code>ca-csr.json</code>檔案，並產生 CA 金鑰：</p>
<pre><code class="sh">$ wget &quot;${PKI_URL}/ca-config.json&quot; &quot;${PKI_URL}/ca-csr.json&quot;
$ cfssl gencert -initca ca-csr.json | cfssljson -bare ca
$ ls ca*.pem
ca-key.pem  ca.pem
</code></pre>
<h4 id="API-Server-Certificate"><a href="#API-Server-Certificate" class="headerlink" title="API Server Certificate"></a>API Server Certificate</h4><p>下載<code>apiserver-csr.json</code>檔案，並產生 kube-apiserver 憑證：</p>
<pre><code class="sh">$ wget &quot;${PKI_URL}/apiserver-csr.json&quot;
$ cfssl gencert \
  -ca=ca.pem \
  -ca-key=ca-key.pem \
  -config=ca-config.json \
  -hostname=10.96.0.1,192.16.35.10,127.0.0.1,kubernetes.default \
  -profile=kubernetes \
  apiserver-csr.json | cfssljson -bare apiserver

$ ls apiserver*.pem
apiserver-key.pem  apiserver.pem
</code></pre>
<blockquote>
<ul>
<li>這邊<code>-hostname</code>的<code>10.96.0.1</code>是 Cluster IP 的 Kubernetes 端點;</li>
<li><code>192.16.35.10</code>為虛擬 IP 位址(VIP);</li>
<li><code>kubernetes.default</code>為 Kubernetes DN。</li>
</ul>
</blockquote>
<h4 id="Front-Proxy-Certificate"><a href="#Front-Proxy-Certificate" class="headerlink" title="Front Proxy Certificate"></a>Front Proxy Certificate</h4><p>下載<code>front-proxy-ca-csr.json</code>檔案，並產生 Front Proxy CA 金鑰，Front Proxy 主要是用在 API aggregator 上:</p>
<pre><code class="sh">$ wget &quot;${PKI_URL}/front-proxy-ca-csr.json&quot;
$ cfssl gencert \
  -initca front-proxy-ca-csr.json | cfssljson -bare front-proxy-ca

$ ls front-proxy-ca*.pem
front-proxy-ca-key.pem  front-proxy-ca.pem
</code></pre>
<p>下載<code>front-proxy-client-csr.json</code>檔案，並產生 front-proxy-client 證書：</p>
<pre><code class="sh">$ wget &quot;${PKI_URL}/front-proxy-client-csr.json&quot;
$ cfssl gencert \
  -ca=front-proxy-ca.pem \
  -ca-key=front-proxy-ca-key.pem \
  -config=ca-config.json \
  -profile=kubernetes \
  front-proxy-client-csr.json | cfssljson -bare front-proxy-client

$ ls front-proxy-client*.pem
front-proxy-client-key.pem  front-proxy-client.pem
</code></pre>
<h4 id="Admin-Certificate"><a href="#Admin-Certificate" class="headerlink" title="Admin Certificate"></a>Admin Certificate</h4><p>下載<code>admin-csr.json</code>檔案，並產生 admin certificate 憑證：</p>
<pre><code class="sh">$ wget &quot;${PKI_URL}/admin-csr.json&quot;
$ cfssl gencert \
  -ca=ca.pem \
  -ca-key=ca-key.pem \
  -config=ca-config.json \
  -profile=kubernetes \
  admin-csr.json | cfssljson -bare admin

$ ls admin*.pem
admin-key.pem  admin.pem
</code></pre>
<p>接著透過以下指令產生名稱為 <code>admin.conf</code> 的 kubeconfig 檔：</p>
<pre><code class="sh"># admin set cluster
$ kubectl config set-cluster kubernetes \
    --certificate-authority=ca.pem \
    --embed-certs=true \
    --server=${KUBE_APISERVER} \
    --kubeconfig=../admin.conf

# admin set credentials
$ kubectl config set-credentials kubernetes-admin \
    --client-certificate=admin.pem \
    --client-key=admin-key.pem \
    --embed-certs=true \
    --kubeconfig=../admin.conf

# admin set context
$ kubectl config set-context kubernetes-admin@kubernetes \
    --cluster=kubernetes \
    --user=kubernetes-admin \
    --kubeconfig=../admin.conf

# admin set default context
$ kubectl config use-context kubernetes-admin@kubernetes \
    --kubeconfig=../admin.conf
</code></pre>
<h4 id="Controller-Manager-Certificate"><a href="#Controller-Manager-Certificate" class="headerlink" title="Controller Manager Certificate"></a>Controller Manager Certificate</h4><p>下載<code>manager-csr.json</code>檔案，並產生 kube-controller-manager certificate 憑證：</p>
<pre><code class="sh">$ wget &quot;${PKI_URL}/manager-csr.json&quot;
$ cfssl gencert \
  -ca=ca.pem \
  -ca-key=ca-key.pem \
  -config=ca-config.json \
  -profile=kubernetes \
  manager-csr.json | cfssljson -bare controller-manager

$ ls controller-manager*.pem
controller-manager-key.pem  controller-manager.pem
</code></pre>
<blockquote>
<p>若節點 IP 不同，需要修改<code>manager-csr.json</code>的<code>hosts</code>。</p>
</blockquote>
<p>接著透過以下指令產生名稱為<code>controller-manager.conf</code>的 kubeconfig 檔：</p>
<pre><code class="sh"># controller-manager set cluster
$ kubectl config set-cluster kubernetes \
    --certificate-authority=ca.pem \
    --embed-certs=true \
    --server=${KUBE_APISERVER} \
    --kubeconfig=../controller-manager.conf

# controller-manager set credentials
$ kubectl config set-credentials system:kube-controller-manager \
    --client-certificate=controller-manager.pem \
    --client-key=controller-manager-key.pem \
    --embed-certs=true \
    --kubeconfig=../controller-manager.conf

# controller-manager set context
$ kubectl config set-context system:kube-controller-manager@kubernetes \
    --cluster=kubernetes \
    --user=system:kube-controller-manager \
    --kubeconfig=../controller-manager.conf

# controller-manager set default context
$ kubectl config use-context system:kube-controller-manager@kubernetes \
    --kubeconfig=../controller-manager.conf
</code></pre>
<h4 id="Scheduler-Certificate"><a href="#Scheduler-Certificate" class="headerlink" title="Scheduler Certificate"></a>Scheduler Certificate</h4><p>下載<code>scheduler-csr.json</code>檔案，並產生 kube-scheduler certificate 憑證：</p>
<pre><code class="sh">$ wget &quot;${PKI_URL}/scheduler-csr.json&quot;
$ cfssl gencert \
  -ca=ca.pem \
  -ca-key=ca-key.pem \
  -config=ca-config.json \
  -profile=kubernetes \
  scheduler-csr.json | cfssljson -bare scheduler

$ ls scheduler*.pem
scheduler-key.pem  scheduler.pem
</code></pre>
<blockquote>
<p>若節點 IP 不同，需要修改<code>scheduler-csr.json</code>的<code>hosts</code>。</p>
</blockquote>
<p>接著透過以下指令產生名稱為 <code>scheduler.conf</code> 的 kubeconfig 檔：</p>
<pre><code class="sh"># scheduler set cluster
$ kubectl config set-cluster kubernetes \
    --certificate-authority=ca.pem \
    --embed-certs=true \
    --server=${KUBE_APISERVER} \
    --kubeconfig=../scheduler.conf

# scheduler set credentials
$ kubectl config set-credentials system:kube-scheduler \
    --client-certificate=scheduler.pem \
    --client-key=scheduler-key.pem \
    --embed-certs=true \
    --kubeconfig=../scheduler.conf

# scheduler set context
$ kubectl config set-context system:kube-scheduler@kubernetes \
    --cluster=kubernetes \
    --user=system:kube-scheduler \
    --kubeconfig=../scheduler.conf

# scheduler use default context
$ kubectl config use-context system:kube-scheduler@kubernetes \
    --kubeconfig=../scheduler.conf
</code></pre>
<h4 id="Master-Kubelet-Certificate"><a href="#Master-Kubelet-Certificate" class="headerlink" title="Master Kubelet Certificate"></a>Master Kubelet Certificate</h4><p>接著在<code>k8s-m1</code>節點下載<code>kubelet-csr.json</code>檔案，並產生所有<code>master</code>節點的憑證：</p>
<pre><code class="sh">$ wget &quot;${PKI_URL}/kubelet-csr.json&quot;
$ for NODE in k8s-m1 k8s-m2 k8s-m3; do
    echo &quot;--- $NODE ---&quot;
    cp kubelet-csr.json kubelet-$NODE-csr.json;
    sed -i &quot;s/\$NODE/$NODE/g&quot; kubelet-$NODE-csr.json;
    cfssl gencert \
      -ca=ca.pem \
      -ca-key=ca-key.pem \
      -config=ca-config.json \
      -hostname=$NODE \
      -profile=kubernetes \
      kubelet-$NODE-csr.json | cfssljson -bare kubelet-$NODE
  done

$ ls kubelet*.pem
kubelet-k8s-m1-key.pem  kubelet-k8s-m1.pem  kubelet-k8s-m2-key.pem  kubelet-k8s-m2.pem  kubelet-k8s-m3-key.pem  kubelet-k8s-m3.pem
</code></pre>
<blockquote>
<p>這邊需要依據節點修改<code>-hostname</code>與<code>$NODE</code>。</p>
</blockquote>
<p>完成後複製 kubelet 憑證至其他<code>master</code>節點：</p>
<pre><code class="sh">$ for NODE in k8s-m2 k8s-m3; do
    echo &quot;--- $NODE ---&quot;
    ssh ${NODE} &quot;mkdir -p /etc/kubernetes/pki&quot;
    for FILE in kubelet-$NODE-key.pem kubelet-$NODE.pem ca.pem; do
      scp /etc/kubernetes/pki/${FILE} ${NODE}:/etc/kubernetes/pki/${FILE}
    done
  done
</code></pre>
<p>接著執行以下指令產生名稱為<code>kubelet.conf</code>的 kubeconfig 檔：</p>
<pre><code class="sh">$ for NODE in k8s-m1 k8s-m2 k8s-m3; do
    echo &quot;--- $NODE ---&quot;
    ssh ${NODE} &quot;cd /etc/kubernetes/pki &amp;&amp; \
      kubectl config set-cluster kubernetes \
        --certificate-authority=ca.pem \
        --embed-certs=true \
        --server=${KUBE_APISERVER} \
        --kubeconfig=../kubelet.conf &amp;&amp; \
      kubectl config set-credentials system:node:${NODE} \
        --client-certificate=kubelet-${NODE}.pem \
        --client-key=kubelet-${NODE}-key.pem \
        --embed-certs=true \
        --kubeconfig=../kubelet.conf &amp;&amp; \
      kubectl config set-context system:node:${NODE}@kubernetes \
        --cluster=kubernetes \
        --user=system:node:${NODE} \
        --kubeconfig=../kubelet.conf &amp;&amp; \
      kubectl config use-context system:node:${NODE}@kubernetes \
        --kubeconfig=../kubelet.conf &amp;&amp; \
      rm kubelet-${NODE}.pem kubelet-${NODE}-key.pem&quot;
  done
</code></pre>
<h4 id="Service-Account-Key"><a href="#Service-Account-Key" class="headerlink" title="Service Account Key"></a>Service Account Key</h4><p>Service account 不是透過 CA 進行認證，因此不要透過 CA 來做 Service account key 的檢查，這邊建立一組 Private 與 Public 金鑰提供給 Service account key 使用：</p>
<pre><code class="sh">$ openssl genrsa -out sa.key 2048
$ openssl rsa -in sa.key -pubout -out sa.pub
$ ls sa.*
sa.key  sa.pub
</code></pre>
<h4 id="刪除不必要檔案"><a href="#刪除不必要檔案" class="headerlink" title="刪除不必要檔案"></a>刪除不必要檔案</h4><p>所有資訊準備完成後，就可以將一些不必要檔案刪除：</p>
<pre><code class="sh">$ rm -rf *.json *.csr scheduler*.pem controller-manager*.pem admin*.pem kubelet*.pem
</code></pre>
<h4 id="複製檔案至其他節點"><a href="#複製檔案至其他節點" class="headerlink" title="複製檔案至其他節點"></a>複製檔案至其他節點</h4><p>複製憑證檔案至其他<code>master</code>節點：</p>
<pre><code class="sh">$ for NODE in k8s-m2 k8s-m3; do
    echo &quot;--- $NODE ---&quot;
    for FILE in $(ls /etc/kubernetes/pki/); do
      scp /etc/kubernetes/pki/${FILE} ${NODE}:/etc/kubernetes/pki/${FILE}
    done
  done
</code></pre>
<p>複製 Kubernetes config 檔案至其他<code>master</code>節點：</p>
<pre><code class="sh">$ for NODE in k8s-m2 k8s-m3; do
    echo &quot;--- $NODE ---&quot;
    for FILE in admin.conf controller-manager.conf scheduler.conf; do
      scp /etc/kubernetes/${FILE} ${NODE}:/etc/kubernetes/${FILE}
    done
  done
</code></pre>
<h2 id="Kubernetes-Masters"><a href="#Kubernetes-Masters" class="headerlink" title="Kubernetes Masters"></a>Kubernetes Masters</h2><p>本部分將說明如何建立與設定 Kubernetes Master 角色，過程中會部署以下元件：</p>
<ul>
<li><strong>kube-apiserver</strong>：提供 REST APIs，包含授權、認證與狀態儲存等。</li>
<li><strong>kube-controller-manager</strong>：負責維護叢集的狀態，如自動擴展，滾動更新等。</li>
<li><strong>kube-scheduler</strong>：負責資源排程，依據預定的排程策略將 Pod 分配到對應節點上。</li>
<li><strong>Etcd</strong>：儲存叢集所有狀態的 Key/Value 儲存系統。</li>
<li><strong>HAProxy</strong>：提供負載平衡器。</li>
<li><strong>Keepalived</strong>：提供虛擬網路位址(VIP)。</li>
</ul>
<h3 id="部署與設定"><a href="#部署與設定" class="headerlink" title="部署與設定"></a>部署與設定</h3><p>首先在<code>所有 master 節點</code>下載部署元件的 YAML 檔案，這邊不採用二進制執行檔與 Systemd 來管理這些元件，全部採用 <a href="https://kubernetes.io/docs/tasks/administer-cluster/static-pod/" target="_blank" rel="noopener">Static Pod</a> 來達成。這邊將檔案下載至<code>/etc/kubernetes/manifests</code>目錄：</p>
<pre><code class="sh">$ export CORE_URL=&quot;https://kairen.github.io/files/manual-v1.10/master&quot;
$ mkdir -p /etc/kubernetes/manifests &amp;&amp; cd /etc/kubernetes/manifests
$ for FILE in kube-apiserver kube-controller-manager kube-scheduler haproxy keepalived etcd etcd.config; do
    wget &quot;${CORE_URL}/${FILE}.yml.conf&quot; -O ${FILE}.yml
    if [ ${FILE} == &quot;etcd.config&quot; ]; then
      mv etcd.config.yml /etc/etcd/etcd.config.yml
      sed -i &quot;s/\${HOSTNAME}/${HOSTNAME}/g&quot; /etc/etcd/etcd.config.yml
      sed -i &quot;s/\${PUBLIC_IP}/$(hostname -i)/g&quot; /etc/etcd/etcd.config.yml
    fi
  done

$ ls /etc/kubernetes/manifests
etcd.yml  haproxy.yml  keepalived.yml  kube-apiserver.yml  kube-controller-manager.yml  kube-scheduler.yml
</code></pre>
<blockquote>
<ul>
<li>若<code>IP</code>與教學設定不同的話，請記得修改 YAML 檔案。</li>
<li>kube-apiserver 中的 <code>NodeRestriction</code> 請參考 <a href="https://kubernetes.io/docs/admin/authorization/node/" target="_blank" rel="noopener">Using Node Authorization</a>。</li>
</ul>
</blockquote>
<p>產生一個用來加密 Etcd 的 Key：</p>
<pre><code class="sh">$ head -c 32 /dev/urandom | base64
SUpbL4juUYyvxj3/gonV5xVEx8j769/99TSAf8YT/sQ=
</code></pre>
<blockquote>
<p>注意每台<code>master</code>節點需要用一樣的 Key。</p>
</blockquote>
<p>在<code>/etc/kubernetes/</code>目錄下，建立<code>encryption.yml</code>的加密 YAML 檔案：</p>
<pre><code class="sh">$ cat &lt;&lt;EOF &gt; /etc/kubernetes/encryption.yml
kind: EncryptionConfig
apiVersion: v1
resources:
  - resources:
      - secrets
    providers:
      - aescbc:
          keys:
            - name: key1
              secret: SUpbL4juUYyvxj3/gonV5xVEx8j769/99TSAf8YT/sQ=
      - identity: {}
EOF
</code></pre>
<blockquote>
<p>Etcd 資料加密可參考這篇 <a href="https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/" target="_blank" rel="noopener">Encrypting data at rest</a>。</p>
</blockquote>
<p>在<code>/etc/kubernetes/</code>目錄下，建立<code>audit-policy.yml</code>的進階稽核策略 YAML 檔：</p>
<pre><code class="sh">$ cat &lt;&lt;EOF &gt; /etc/kubernetes/audit-policy.yml
apiVersion: audit.k8s.io/v1beta1
kind: Policy
rules:
- level: Metadata
EOF
</code></pre>
<blockquote>
<p>Audit Policy 請參考這篇 <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/audit/" target="_blank" rel="noopener">Auditing</a>。</p>
</blockquote>
<p>下載<code>haproxy.cfg</code>檔案來提供給 HAProxy 容器使用：</p>
<pre><code class="sh">$ mkdir -p /etc/haproxy/
$ wget &quot;${CORE_URL}/haproxy.cfg&quot; -O /etc/haproxy/haproxy.cfg
</code></pre>
<blockquote>
<p>若與本教學 IP 不同的話，請記得修改設定檔。</p>
</blockquote>
<p>下載<code>kubelet.service</code>相關檔案來管理 kubelet：</p>
<pre><code class="sh">$ mkdir -p /etc/systemd/system/kubelet.service.d
$ wget &quot;${CORE_URL}/kubelet.service&quot; -O /lib/systemd/system/kubelet.service
$ wget &quot;${CORE_URL}/10-kubelet.conf&quot; -O /etc/systemd/system/kubelet.service.d/10-kubelet.conf
</code></pre>
<blockquote>
<p>若 cluster <code>dns</code>或<code>domain</code>有改變的話，需要修改<code>10-kubelet.conf</code>。</p>
</blockquote>
<p>最後建立 var 存放資訊，然後啟動 kubelet 服務:</p>
<pre><code class="sh">$ mkdir -p /var/lib/kubelet /var/log/kubernetes /var/lib/etcd
$ systemctl enable kubelet.service &amp;&amp; systemctl start kubelet.service
</code></pre>
<p>完成後會需要一段時間來下載映像檔與啟動元件，可以利用該指令來監看：</p>
<pre><code class="sh">$ watch netstat -ntlp
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        0      0 127.0.0.1:10248         0.0.0.0:*               LISTEN      10344/kubelet
tcp        0      0 127.0.0.1:10251         0.0.0.0:*               LISTEN      11324/kube-schedule
tcp        0      0 0.0.0.0:6443            0.0.0.0:*               LISTEN      11416/haproxy
tcp        0      0 127.0.0.1:10252         0.0.0.0:*               LISTEN      11235/kube-controll
tcp        0      0 0.0.0.0:9090            0.0.0.0:*               LISTEN      11416/haproxy
tcp6       0      0 :::2379                 :::*                    LISTEN      10479/etcd
tcp6       0      0 :::2380                 :::*                    LISTEN      10479/etcd
tcp6       0      0 :::10255                :::*                    LISTEN      10344/kubelet
tcp6       0      0 :::5443                 :::*                    LISTEN      11295/kube-apiserve
</code></pre>
<blockquote>
<p>若看到以上資訊表示服務正常啟動，若發生問題可以用<code>docker</code>指令來查看。</p>
</blockquote>
<h3 id="驗證叢集"><a href="#驗證叢集" class="headerlink" title="驗證叢集"></a>驗證叢集</h3><p>完成後，在任意一台<code>master</code>節點複製 admin kubeconfig 檔案，並透過簡單指令驗證：</p>
<pre><code class="sh">$ cp /etc/kubernetes/admin.conf ~/.kube/config
$ kubectl get cs
NAME                 STATUS    MESSAGE              ERROR
controller-manager   Healthy   ok
scheduler            Healthy   ok
etcd-2               Healthy   {&quot;health&quot;: &quot;true&quot;}
etcd-1               Healthy   {&quot;health&quot;: &quot;true&quot;}
etcd-0               Healthy   {&quot;health&quot;: &quot;true&quot;}

$ kubectl get node
NAME      STATUS     ROLES     AGE       VERSION
k8s-m1    NotReady   master    52s       v1.10.0
k8s-m2    NotReady   master    51s       v1.10.0
k8s-m3    NotReady   master    50s       v1.10.0

$ kubectl -n kube-system get po
NAME                             READY     STATUS    RESTARTS   AGE
etcd-k8s-m1                      1/1       Running   0          7s
etcd-k8s-m2                      1/1       Running   0          57s
haproxy-k8s-m3                   1/1       Running   0          1m
...
</code></pre>
<p>接著確認服務能夠執行 logs 等指令：</p>
<pre><code class="sh">$ kubectl -n kube-system logs -f kube-scheduler-k8s-m2
Error from server (Forbidden): Forbidden (user=kube-apiserver, verb=get, resource=nodes, subresource=proxy) ( pods/log kube-scheduler-k8s-m2)
</code></pre>
<blockquote>
<p>這邊會發現出現 403 Forbidden 問題，這是因為 <code>kube-apiserver</code> user 並沒有 nodes 的資源存取權限，屬於正常。</p>
</blockquote>
<p>由於上述權限問題，必需建立一個<code>apiserver-to-kubelet-rbac.yml</code>來定義權限，以供對 Nodes 容器執行 logs、exec 等指令。在任意一台<code>master</code>節點執行以下指令：</p>
<pre><code class="sh">$ kubectl apply -f &quot;${CORE_URL}/apiserver-to-kubelet-rbac.yml.conf&quot;
clusterrole.rbac.authorization.k8s.io &quot;system:kube-apiserver-to-kubelet&quot; configured
clusterrolebinding.rbac.authorization.k8s.io &quot;system:kube-apiserver&quot; configured

# 測試 logs
$ kubectl -n kube-system logs -f kube-scheduler-k8s-m2
...
I0403 02:30:36.375935       1 server.go:555] Version: v1.10.0
I0403 02:30:36.378208       1 server.go:574] starting healthz server on 127.0.0.1:10251
</code></pre>
<p>設定<code>master</code>節點允許 Taint：</p>
<pre><code class="sh">$ kubectl taint nodes node-role.kubernetes.io/master=&quot;&quot;:NoSchedule --all
node &quot;k8s-m1&quot; tainted
node &quot;k8s-m2&quot; tainted
node &quot;k8s-m3&quot; tainted
</code></pre>
<blockquote>
<p><a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/" target="_blank" rel="noopener">Taints and Tolerations</a>。</p>
</blockquote>
<h3 id="建立-TLS-Bootstrapping-RBAC-與-Secret"><a href="#建立-TLS-Bootstrapping-RBAC-與-Secret" class="headerlink" title="建立 TLS Bootstrapping RBAC 與 Secret"></a>建立 TLS Bootstrapping RBAC 與 Secret</h3><p>由於本次安裝啟用了 TLS 認證，因此每個節點的 kubelet 都必須使用 kube-apiserver 的 CA 的憑證後，才能與 kube-apiserver 進行溝通，而該過程需要手動針對每台節點單獨簽署憑證是一件繁瑣的事情，且一旦節點增加會延伸出管理不易問題; 而 TLS bootstrapping 目標就是解決該問題，透過讓 kubelet 先使用一個預定低權限使用者連接到 kube-apiserver，然後在對 kube-apiserver 申請憑證簽署，當授權 Token 一致時，Node 節點的 kubelet 憑證將由 kube-apiserver 動態簽署提供。具體作法可以參考 <a href="https://kubernetes.io/docs/admin/kubelet-tls-bootstrapping/" target="_blank" rel="noopener">TLS Bootstrapping</a> 與 <a href="https://kubernetes.io/docs/admin/bootstrap-tokens/" target="_blank" rel="noopener">Authenticating with Bootstrap Tokens</a>。</p>
<p>首先在<code>k8s-m1</code>建立一個變數來產生<code>BOOTSTRAP_TOKEN</code>，並建立<code>bootstrap-kubelet.conf</code>的 Kubernetes config 檔：</p>
<pre><code class="sh">$ cd /etc/kubernetes/pki
$ export TOKEN_ID=$(openssl rand 3 -hex)
$ export TOKEN_SECRET=$(openssl rand 8 -hex)
$ export BOOTSTRAP_TOKEN=${TOKEN_ID}.${TOKEN_SECRET}
$ export KUBE_APISERVER=&quot;https://192.16.35.10:6443&quot;

# bootstrap set cluster
$ kubectl config set-cluster kubernetes \
    --certificate-authority=ca.pem \
    --embed-certs=true \
    --server=${KUBE_APISERVER} \
    --kubeconfig=../bootstrap-kubelet.conf

# bootstrap set credentials
$ kubectl config set-credentials tls-bootstrap-token-user \
    --token=${BOOTSTRAP_TOKEN} \
    --kubeconfig=../bootstrap-kubelet.conf

# bootstrap set context
$ kubectl config set-context tls-bootstrap-token-user@kubernetes \
    --cluster=kubernetes \
    --user=tls-bootstrap-token-user \
    --kubeconfig=../bootstrap-kubelet.conf

# bootstrap use default context
$ kubectl config use-context tls-bootstrap-token-user@kubernetes \
    --kubeconfig=../bootstrap-kubelet.conf
</code></pre>
<blockquote>
<p>若想要用手動簽署憑證來進行授權的話，可以參考 <a href="https://kubernetes.io/docs/concepts/cluster-administration/certificates/" target="_blank" rel="noopener">Certificate</a>。</p>
</blockquote>
<p>接著在<code>k8s-m1</code>建立 TLS bootstrap secret 來提供自動簽證使用：</p>
<pre><code class="sh">$ cat &lt;&lt;EOF | kubectl create -f -
apiVersion: v1
kind: Secret
metadata:
  name: bootstrap-token-${TOKEN_ID}
  namespace: kube-system
type: bootstrap.kubernetes.io/token
stringData:
  token-id: ${TOKEN_ID}
  token-secret: ${TOKEN_SECRET}
  usage-bootstrap-authentication: &quot;true&quot;
  usage-bootstrap-signing: &quot;true&quot;
  auth-extra-groups: system:bootstrappers:default-node-token
EOF

secret &quot;bootstrap-token-65a3a9&quot; created
</code></pre>
<p>在<code>k8s-m1</code>建立 TLS Bootstrap Autoapprove RBAC：</p>
<pre><code class="sh">$ kubectl apply -f &quot;${CORE_URL}/kubelet-bootstrap-rbac.yml.conf&quot;
clusterrolebinding.rbac.authorization.k8s.io &quot;kubelet-bootstrap&quot; created
clusterrolebinding.rbac.authorization.k8s.io &quot;node-autoapprove-bootstrap&quot; created
clusterrolebinding.rbac.authorization.k8s.io &quot;node-autoapprove-certificate-rotation&quot; created
</code></pre>
<h2 id="Kubernetes-Nodes"><a href="#Kubernetes-Nodes" class="headerlink" title="Kubernetes Nodes"></a>Kubernetes Nodes</h2><p>本部分將說明如何建立與設定 Kubernetes Node 角色，Node 是主要執行容器實例(Pod)的工作節點。</p>
<p>在開始部署前，先在<code>k8-m1</code>將需要用到的檔案複製到所有<code>node</code>節點上：</p>
<pre><code class="sh">$ cd /etc/kubernetes/pki
$ for NODE in k8s-n1 k8s-n2 k8s-n3; do
    echo &quot;--- $NODE ---&quot;
    ssh ${NODE} &quot;mkdir -p /etc/kubernetes/pki/&quot;
    ssh ${NODE} &quot;mkdir -p /etc/etcd/ssl&quot;
    # Etcd
    for FILE in etcd-ca.pem etcd.pem etcd-key.pem; do
      scp /etc/etcd/ssl/${FILE} ${NODE}:/etc/etcd/ssl/${FILE}
    done
    # Kubernetes
    for FILE in pki/ca.pem pki/ca-key.pem bootstrap-kubelet.conf; do
      scp /etc/kubernetes/${FILE} ${NODE}:/etc/kubernetes/${FILE}
    done
  done
</code></pre>
<h3 id="部署與設定-1"><a href="#部署與設定-1" class="headerlink" title="部署與設定"></a>部署與設定</h3><p>在每台<code>node</code>節點下載<code>kubelet.service</code>相關檔案來管理 kubelet：</p>
<pre><code class="sh">$ export CORE_URL=&quot;https://kairen.github.io/files/manual-v1.10/node&quot;
$ mkdir -p /etc/systemd/system/kubelet.service.d
$ wget &quot;${CORE_URL}/kubelet.service&quot; -O /lib/systemd/system/kubelet.service
$ wget &quot;${CORE_URL}/10-kubelet.conf&quot; -O /etc/systemd/system/kubelet.service.d/10-kubelet.conf
</code></pre>
<blockquote>
<p>若 cluster <code>dns</code>或<code>domain</code>有改變的話，需要修改<code>10-kubelet.conf</code>。</p>
</blockquote>
<p>最後建立 var 存放資訊，然後啟動 kubelet 服務:</p>
<pre><code class="sh">$ mkdir -p /var/lib/kubelet /var/log/kubernetes
$ systemctl enable kubelet.service &amp;&amp; systemctl start kubelet.service
</code></pre>
<h3 id="驗證叢集-1"><a href="#驗證叢集-1" class="headerlink" title="驗證叢集"></a>驗證叢集</h3><p>完成後，在任意一台<code>master</code>節點並透過簡單指令驗證：</p>
<pre><code class="sh">$ kubectl get csr
NAME                                                   AGE       REQUESTOR                 CONDITION
csr-bvz9l                                              11m       system:node:k8s-m1        Approved,Issued
csr-jwr8k                                              11m       system:node:k8s-m2        Approved,Issued
csr-q867w                                              11m       system:node:k8s-m3        Approved,Issued
node-csr-Y-FGvxZWJqI-8RIK_IrpgdsvjGQVGW0E4UJOuaU8ogk   17s       system:bootstrap:dca3e1   Approved,Issued
node-csr-cnX9T1xp1LdxVDc9QW43W0pYkhEigjwgceRshKuI82c   19s       system:bootstrap:dca3e1   Approved,Issued
node-csr-m7SBA9RAGCnsgYWJB-u2HoB2qLSfiQZeAxWFI2WYN7Y   18s       system:bootstrap:dca3e1   Approved,Issued

$ kubectl get nodes
NAME      STATUS     ROLES     AGE       VERSION
k8s-m1    NotReady   master    12m       v1.10.0
k8s-m2    NotReady   master    11m       v1.10.0
k8s-m3    NotReady   master    11m       v1.10.0
k8s-n1    NotReady   node      32s       v1.10.0
k8s-n2    NotReady   node      31s       v1.10.0
k8s-n3    NotReady   node      29s       v1.10.0
</code></pre>
<h2 id="Kubernetes-Core-Addons-部署"><a href="#Kubernetes-Core-Addons-部署" class="headerlink" title="Kubernetes Core Addons 部署"></a>Kubernetes Core Addons 部署</h2><p>當完成上面所有步驟後，接著需要部署一些插件，其中如<code>Kubernetes DNS</code>與<code>Kubernetes Proxy</code>等這種 Addons 是非常重要的。</p>
<h3 id="Kubernetes-Proxy"><a href="#Kubernetes-Proxy" class="headerlink" title="Kubernetes Proxy"></a>Kubernetes Proxy</h3><p><a href="https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/kube-proxy" target="_blank" rel="noopener">Kube-proxy</a> 是實現 Service 的關鍵插件，kube-proxy 會在每台節點上執行，然後監聽 API Server 的 Service 與 Endpoint 資源物件的改變，然後來依據變化執行 iptables 來實現網路的轉發。</p>
<p>在<code>k8s-m1</code>下載<code>kube-proxy.yml</code>來建立 Kubernetes Proxy Addon：</p>
<pre><code class="sh">$ kubectl apply -f &quot;https://kairen.github.io/files/manual-v1.10/addon/kube-proxy.yml.conf&quot;
serviceaccount &quot;kube-proxy&quot; created
clusterrolebinding.rbac.authorization.k8s.io &quot;system:kube-proxy&quot; created
configmap &quot;kube-proxy&quot; created
daemonset.apps &quot;kube-proxy&quot; created

$ kubectl -n kube-system get po -o wide -l k8s-app=kube-proxy
NAME               READY     STATUS    RESTARTS   AGE       IP             NODE
kube-proxy-8j5w8   1/1       Running   0          29s       192.16.35.16   k8s-n3
kube-proxy-c4zvt   1/1       Running   0          29s       192.16.35.11   k8s-m1
kube-proxy-clpl6   1/1       Running   0          29s       192.16.35.12   k8s-m2
...
</code></pre>
<h3 id="Kubernetes-DNS"><a href="#Kubernetes-DNS" class="headerlink" title="Kubernetes DNS"></a>Kubernetes DNS</h3><p><a href="https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dns" target="_blank" rel="noopener">Kube DNS</a> 是 Kubernetes 叢集內部 Pod 之間互相溝通的重要 Addon，它允許 Pod 可以透過 Domain Name 方式來連接 Service，其主要由 Kube DNS 與 Sky DNS 組合而成，透過 Kube DNS 監聽 Service 與 Endpoint 變化，來提供給 Sky DNS 資訊，已更新解析位址。</p>
<p>在<code>k8s-m1</code>下載<code>kube-proxy.yml</code>來建立 Kubernetes Proxy Addon：</p>
<pre><code class="sh">$ kubectl apply -f &quot;https://kairen.github.io/files/manual-v1.10/addon/kube-dns.yml.conf&quot;
serviceaccount &quot;kube-dns&quot; created
service &quot;kube-dns&quot; created
deployment.extensions &quot;kube-dns&quot; created

$ kubectl -n kube-system get po -l k8s-app=kube-dns
NAME                        READY     STATUS    RESTARTS   AGE
kube-dns-654684d656-zq5t8   0/3       Pending   0          1m
</code></pre>
<p>這邊會發現處於<code>Pending</code>狀態，是由於 Kubernetes Pod Network 還未建立完成，因此所有節點會處於<code>NotReady</code>狀態，而造成 Pod 無法被排程分配到指定節點上啟動，由於為了解決該問題，下節將說明如何建立 Pod Network。</p>
<h2 id="Calico-Network-安裝與設定"><a href="#Calico-Network-安裝與設定" class="headerlink" title="Calico Network 安裝與設定"></a>Calico Network 安裝與設定</h2><p>Calico 是一款純 Layer 3 的資料中心網路方案(不需要 Overlay 網路)，Calico 好處是它整合了各種雲原生平台，且 Calico 在每一個節點利用 Linux Kernel 實現高效的 vRouter 來負責資料的轉發，而當資料中心複雜度增加時，可以用 BGP route reflector 來達成。</p>
<blockquote>
<p>本次不採用手動方式來建立 Calico 網路，若想了解可以參考 <a href="https://docs.projectcalico.org/v3.0/getting-started/kubernetes/installation/integration" target="_blank" rel="noopener">Integration Guide</a>。</p>
</blockquote>
<p>在<code>k8s-m1</code>下載<code>calico.yaml</code>來建立 Calico Network：</p>
<pre><code class="sh">$ kubectl apply -f &quot;https://kairen.github.io/files/manual-v1.10/network/calico.yml.conf&quot;
configmap &quot;calico-config&quot; created
daemonset &quot;calico-node&quot; created
deployment &quot;calico-kube-controllers&quot; created
clusterrolebinding &quot;calico-cni-plugin&quot; created
clusterrole &quot;calico-cni-plugin&quot; created
serviceaccount &quot;calico-cni-plugin&quot; created
clusterrolebinding &quot;calico-kube-controllers&quot; created
clusterrole &quot;calico-kube-controllers&quot; created
serviceaccount &quot;calico-kube-controllers&quot; created

$ kubectl -n kube-system get po -l k8s-app=calico-node -o wide
NAME                READY     STATUS    RESTARTS   AGE       IP             NODE
calico-node-22mbb   2/2       Running   0          1m        192.16.35.12   k8s-m2
calico-node-2qwf5   2/2       Running   0          1m        192.16.35.11   k8s-m1
calico-node-g2sp8   2/2       Running   0          1m        192.16.35.13   k8s-m3
calico-node-hghp4   2/2       Running   0          1m        192.16.35.14   k8s-n1
calico-node-qp6gf   2/2       Running   0          1m        192.16.35.15   k8s-n2
calico-node-zfx4n   2/2       Running   0          1m        192.16.35.16   k8s-n3
</code></pre>
<blockquote>
<p>這邊若節點 IP 與網卡不同的話，請修改<code>calico.yml</code>檔案。</p>
</blockquote>
<p>在<code>k8s-m1</code>下載 Calico CLI 來查看 Calico nodes:</p>
<pre><code class="sh">$ wget https://github.com/projectcalico/calicoctl/releases/download/v3.1.0/calicoctl -O /usr/local/bin/calicoctl
$ chmod u+x /usr/local/bin/calicoctl
$ cat &lt;&lt;EOF &gt; ~/calico-rc
export ETCD_ENDPOINTS=&quot;https://192.16.35.11:2379,https://192.16.35.12:2379,https://192.16.35.13:2379&quot;
export ETCD_CA_CERT_FILE=&quot;/etc/etcd/ssl/etcd-ca.pem&quot;
export ETCD_CERT_FILE=&quot;/etc/etcd/ssl/etcd.pem&quot;
export ETCD_KEY_FILE=&quot;/etc/etcd/ssl/etcd-key.pem&quot;
EOF

$ . ~/calico-rc
$ calicoctl node status
Calico process is running.

IPv4 BGP status
+--------------+-------------------+-------+----------+-------------+
| PEER ADDRESS |     PEER TYPE     | STATE |  SINCE   |    INFO     |
+--------------+-------------------+-------+----------+-------------+
| 192.16.35.12 | node-to-node mesh | up    | 04:42:37 | Established |
| 192.16.35.13 | node-to-node mesh | up    | 04:42:42 | Established |
| 192.16.35.14 | node-to-node mesh | up    | 04:42:37 | Established |
| 192.16.35.15 | node-to-node mesh | up    | 04:42:41 | Established |
| 192.16.35.16 | node-to-node mesh | up    | 04:42:36 | Established |
+--------------+-------------------+-------+----------+-------------+
...
</code></pre>
<p>查看 pending 的 pod 是否已執行：</p>
<pre><code class="sh">$ kubectl -n kube-system get po -l k8s-app=kube-dns
kubectl -n kube-system get po -l k8s-app=kube-dns
NAME                        READY     STATUS    RESTARTS   AGE
kube-dns-654684d656-j8xzx   3/3       Running   0          10m
</code></pre>
<h2 id="Kubernetes-Extra-Addons-部署"><a href="#Kubernetes-Extra-Addons-部署" class="headerlink" title="Kubernetes Extra Addons 部署"></a>Kubernetes Extra Addons 部署</h2><p>本節說明如何部署一些官方常用的 Addons，如 Dashboard、Heapster 等。</p>
<h3 id="Dashboard"><a href="#Dashboard" class="headerlink" title="Dashboard"></a>Dashboard</h3><p><a href="https://github.com/kubernetes/dashboard" target="_blank" rel="noopener">Dashboard</a> 是 Kubernetes 社區官方開發的儀表板，有了儀表板後管理者就能夠透過 Web-based 方式來管理 Kubernetes 叢集，除了提升管理方便，也讓資源視覺化，讓人更直覺看見系統資訊的呈現結果。</p>
<p>在<code>k8s-m1</code>透過 kubectl 來建立 kubernetes dashboard 即可：</p>
<pre><code class="sh">$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml
$ kubectl -n kube-system get po,svc -l k8s-app=kubernetes-dashboard
NAME                                    READY     STATUS    RESTARTS   AGE
kubernetes-dashboard-7d5dcdb6d9-j492l   1/1       Running   0          12s

NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
kubernetes-dashboard   ClusterIP   10.111.22.111   &lt;none&gt;        443/TCP   12s
</code></pre>
<p>這邊會額外建立一個名稱為<code>open-api</code> Cluster Role Binding，這僅作為方便測試時使用，在一般情況下不要開啟，不然就會直接被存取所有 API:</p>
<pre><code class="sh">$ cat &lt;&lt;EOF | kubectl create -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: open-api
  namespace: &quot;&quot;
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:anonymous
EOF
</code></pre>
<blockquote>
<p>注意!管理者可以針對特定使用者來開放 API 存取權限，但這邊方便使用直接綁在 cluster-admin cluster role。</p>
</blockquote>
<p>完成後，就可以透過瀏覽器存取 <a href="https://192.16.35.10:6443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/" target="_blank" rel="noopener">Dashboard</a>。</p>
<p>在 1.7 版本以後的 Dashboard 將不再提供所有權限，因此需要建立一個 service account 來綁定 cluster-admin role：</p>
<pre><code class="sh">$ kubectl -n kube-system create sa dashboard
$ kubectl create clusterrolebinding dashboard --clusterrole cluster-admin --serviceaccount=kube-system:dashboard
$ SECRET=$(kubectl -n kube-system get sa dashboard -o yaml | awk &#39;/dashboard-token/ {print $3}&#39;)
$ kubectl -n kube-system describe secrets ${SECRET} | awk &#39;/token:/{print $2}&#39;
eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtdG9rZW4tdzVocmgiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiYWJmMTFjYzMtZjRlYi0xMWU3LTgzYWUtMDgwMDI3NjdkOWI5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZCJ9.Xuyq34ci7Mk8bI97o4IldDyKySOOqRXRsxVWIJkPNiVUxKT4wpQZtikNJe2mfUBBD-JvoXTzwqyeSSTsAy2CiKQhekW8QgPLYelkBPBibySjBhJpiCD38J1u7yru4P0Pww2ZQJDjIxY4vqT46ywBklReGVqY3ogtUQg-eXueBmz-o7lJYMjw8L14692OJuhBjzTRSaKW8U2MPluBVnD7M2SOekDff7KpSxgOwXHsLVQoMrVNbspUCvtIiEI1EiXkyCNRGwfnd2my3uzUABIHFhm0_RZSmGwExPbxflr8Fc6bxmuz-_jSdOtUidYkFIzvEWw2vRovPgs3MXTv59RwUw
</code></pre>
<blockquote>
<p>複製<code>token</code>，然後貼到 Kubernetes dashboard。注意這邊一般來說要針對不同 User 開啟特定存取權限。</p>
</blockquote>
<p><img src="/images/kube/kubernetes-dashboard.png" alt></p>
<h3 id="Heapster"><a href="#Heapster" class="headerlink" title="Heapster"></a>Heapster</h3><p><a href="https://github.com/kubernetes/heapster" target="_blank" rel="noopener">Heapster</a> 是 Kubernetes 社區維護的容器叢集監控與效能分析工具。Heapster 會從 Kubernetes apiserver 取得所有 Node 資訊，然後再透過這些 Node 來取得 kubelet 上的資料，最後再將所有收集到資料送到 Heapster 的後台儲存 InfluxDB，最後利用 Grafana 來抓取 InfluxDB 的資料源來進行視覺化。</p>
<p>在<code>k8s-m1</code>透過 kubectl 來建立 kubernetes monitor  即可：</p>
<pre><code class="sh">$ kubectl apply -f &quot;https://kairen.github.io/files/manual-v1.10/addon/kube-monitor.yml.conf&quot;
$ kubectl -n kube-system get po,svc
NAME                                           READY     STATUS    RESTARTS   AGE
...
po/heapster-74fb5c8cdc-62xzc                   4/4       Running   0          7m
po/influxdb-grafana-55bd7df44-nw4nc            2/2       Running   0          7m

NAME                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
...
svc/heapster               ClusterIP   10.100.242.225   &lt;none&gt;        80/TCP              7m
svc/monitoring-grafana     ClusterIP   10.101.106.180   &lt;none&gt;        80/TCP              7m
svc/monitoring-influxdb    ClusterIP   10.109.245.142   &lt;none&gt;        8083/TCP,8086/TCP   7m
···
</code></pre>
<p>完成後，就可以透過瀏覽器存取 <a href="https://192.16.35.10:6443/api/v1/namespaces/kube-system/services/monitoring-grafana/proxy/" target="_blank" rel="noopener">Grafana Dashboard</a>。</p>
<p><img src="/images/kube/monitoring-grafana.png" alt></p>
<h3 id="Ingress-Controller"><a href="#Ingress-Controller" class="headerlink" title="Ingress Controller"></a>Ingress Controller</h3><p><a href="https://kubernetes.io/docs/concepts/services-networking/ingress/" target="_blank" rel="noopener">Ingress</a>是利用 Nginx 或 HAProxy 等負載平衡器來曝露叢集內服務的元件，Ingress 主要透過設定 Ingress 規則來定義 Domain Name 映射 Kubernetes 內部 Service，這種方式可以避免掉使用過多的 NodePort 問題。</p>
<p>在<code>k8s-m1</code>透過 kubectl 來建立 Ingress Controller 即可：</p>
<pre><code class="sh">$ kubectl create ns ingress-nginx
$ kubectl apply -f &quot;https://kairen.github.io/files/manual-v1.10/addon/ingress-controller.yml.conf&quot;
$ kubectl -n ingress-nginx get po
NAME                                       READY     STATUS    RESTARTS   AGE
default-http-backend-5c6d95c48-rzxfb       1/1       Running   0          7m
nginx-ingress-controller-699cdf846-982n4   1/1       Running   0          7m
</code></pre>
<blockquote>
<p>這裡也可以選擇 <a href="https://github.com/containous/traefik" target="_blank" rel="noopener">Traefik</a> 的 Ingress Controller。</p>
</blockquote>
<h4 id="測試-Ingress-功能"><a href="#測試-Ingress-功能" class="headerlink" title="測試 Ingress 功能"></a>測試 Ingress 功能</h4><p>這邊先建立一個 Nginx HTTP server Deployment 與 Service：</p>
<pre><code class="sh">$ kubectl run nginx-dp --image nginx --port 80
$ kubectl expose deploy nginx-dp --port 80
$ kubectl get po,svc
$ cat &lt;&lt;EOF | kubectl create -f -
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: test-nginx-ingress
  annotations:
    ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: test.nginx.com
    http:
      paths:
      - path: /
        backend:
          serviceName: nginx-dp
          servicePort: 80
EOF
</code></pre>
<p>透過 curl 來進行測試：</p>
<pre><code class="sh">$ curl 192.16.35.10 -H &#39;Host: test.nginx.com&#39;
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
...

# 測試其他 domain name 是否會回傳 404
$ curl 192.16.35.10 -H &#39;Host: test.nginx.com1&#39;
default backend - 404
</code></pre>
<h3 id="Helm-Tiller-Server"><a href="#Helm-Tiller-Server" class="headerlink" title="Helm Tiller Server"></a>Helm Tiller Server</h3><p><a href="https://github.com/kubernetes/helm" target="_blank" rel="noopener">Helm</a> 是 Kubernetes Chart 的管理工具，Kubernetes Chart 是一套預先組態的 Kubernetes 資源套件。其中<code>Tiller Server</code>主要負責接收來至 Client 的指令，並透過 kube-apiserver 與 Kubernetes 叢集做溝通，根據 Chart 定義的內容，來產生與管理各種對應 API 物件的 Kubernetes 部署檔案(又稱為 <code>Release</code>)。</p>
<p>首先在<code>k8s-m1</code>安裝 Helm tool：</p>
<pre><code class="sh">$ wget -qO- https://kubernetes-helm.storage.googleapis.com/helm-v2.8.1-linux-amd64.tar.gz | tar -zx
$ sudo mv linux-amd64/helm /usr/local/bin/
</code></pre>
<p>另外在所有<code>node</code>節點安裝 socat：</p>
<pre><code class="sh">$ sudo apt-get install -y socat
</code></pre>
<p>接著初始化 Helm(這邊會安裝 Tiller Server)：</p>
<pre><code class="sh">$ kubectl -n kube-system create sa tiller
$ kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller
$ helm init --service-account tiller
...
Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster.
Happy Helming!

$ kubectl -n kube-system get po -l app=helm
NAME                             READY     STATUS    RESTARTS   AGE
tiller-deploy-5f789bd9f7-tzss6   1/1       Running   0          29s

$ helm version
Client: &amp;version.Version{SemVer:&quot;v2.8.1&quot;, GitCommit:&quot;6af75a8fd72e2aa18a2b278cfe5c7a1c5feca7f2&quot;, GitTreeState:&quot;clean&quot;}
Server: &amp;version.Version{SemVer:&quot;v2.8.1&quot;, GitCommit:&quot;6af75a8fd72e2aa18a2b278cfe5c7a1c5feca7f2&quot;, GitTreeState:&quot;clean&quot;}
</code></pre>
<h4 id="測試-Helm-功能"><a href="#測試-Helm-功能" class="headerlink" title="測試 Helm 功能"></a>測試 Helm 功能</h4><p>這邊部署簡單 Jenkins 來進行功能測試：</p>
<pre><code class="sh">$ helm install --name demo --set Persistence.Enabled=false stable/jenkins
$ kubectl get po,svc  -l app=demo-jenkins
NAME                           READY     STATUS    RESTARTS   AGE
demo-jenkins-7bf4bfcff-q74nt   1/1       Running   0          2m

NAME                 TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
demo-jenkins         LoadBalancer   10.103.15.129    &lt;pending&gt;     8080:31161/TCP   2m
demo-jenkins-agent   ClusterIP      10.103.160.126   &lt;none&gt;        50000/TCP        2m

# 取得 admin 帳號的密碼
$ printf $(kubectl get secret --namespace default demo-jenkins -o jsonpath=&quot;{.data.jenkins-admin-password}&quot; | base64 --decode);echo
r6y9FMuF2u
</code></pre>
<p>完成後，就可以透過瀏覽器存取 <a href="http://192.16.35.10:31161" target="_blank" rel="noopener">Jenkins Web</a>。</p>
<p><img src="/images/kube/helm-jenkins-v1.10.png" alt></p>
<p>測試完成後，即可刪除：</p>
<pre><code class="sh">$ helm ls
NAME    REVISION    UPDATED                     STATUS      CHART             NAMESPACE
demo    1           Tue Apr 10 07:29:51 2018    DEPLOYED    jenkins-0.14.4    default

$ helm delete demo --purge
release &quot;demo&quot; deleted
</code></pre>
<p>更多 Helm Apps 可以到 <a href="https://hub.kubeapps.com/" target="_blank" rel="noopener">Kubeapps Hub</a> 尋找。</p>
<h2 id="測試叢集"><a href="#測試叢集" class="headerlink" title="測試叢集"></a>測試叢集</h2><p>SSH 進入<code>k8s-m1</code>節點，然後關閉該節點：</p>
<pre><code class="sh">$ sudo poweroff
</code></pre>
<p>接著進入到<code>k8s-m2</code>節點，透過 kubectl 來檢查叢集是否能夠正常執行：</p>
<pre><code class="sh"># 先檢查 etcd 狀態，可以發現 etcd-0 因為關機而中斷
$ kubectl get cs
NAME                 STATUS      MESSAGE                                                                                                                                          ERROR
scheduler            Healthy     ok
controller-manager   Healthy     ok
etcd-1               Healthy     {&quot;health&quot;: &quot;true&quot;}
etcd-2               Healthy     {&quot;health&quot;: &quot;true&quot;}
etcd-0               Unhealthy   Get https://192.16.35.11:2379/health: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)

# 測試是否可以建立 Pod
$ kubectl run nginx --image nginx --restart=Never --port 80
$ kubectl get po
NAME      READY     STATUS    RESTARTS   AGE
nginx     1/1       Running   0          22s
</code></pre>

                

                <hr>
                <!-- Pager -->
                <ul class="pager">
                    
                        <li class="previous">
                            <a href="/2018/04/15/kubernetes/k8s-integration-ldap/" data-toggle="tooltip" data-placement="top" title="整合 Open LDAP 進行 Kubernetes 身份認證">&larr; Previous Post</a>
                        </li>
                    
                    
                        <li class="next">
                            <a href="/2018/03/21/kubernetes/k8s-federation/" data-toggle="tooltip" data-placement="top" title="使用 kubefed 建立 Kubernetes Federation(On-premises)">Next Post &rarr;</a>
                        </li>
                    
                </ul>

                <!-- duoshuo Share start -->
                
                <!-- 多说 Share end-->

                <!-- 多说评论框 start -->
                
                <!-- 多说评论框 end -->

                <!-- disqus comment start -->
                
                    <div class="comment">
                        <div id="disqus_thread" class="disqus-thread"></div>
                    </div>
                
                <!-- disqus comment end -->
            </div>
            
            <!-- Tabe of Content -->
            <!-- Table of Contents -->

    
      <aside id="sidebar">
        <div id="toc" class="toc-article">
        <strong class="toc-title">Contents</strong>
        
          <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#節點資訊"><span class="toc-nav-number">1.</span> <span class="toc-nav-text">節點資訊</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#事前準備"><span class="toc-nav-number">2.</span> <span class="toc-nav-text">事前準備</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#建立叢集-CA-keys-與-Certificates"><span class="toc-nav-number">3.</span> <span class="toc-nav-text">建立叢集 CA keys 與 Certificates</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Etcd"><span class="toc-nav-number">3.1.</span> <span class="toc-nav-text">Etcd</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Kubernetes"><span class="toc-nav-number">3.2.</span> <span class="toc-nav-text">Kubernetes</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#API-Server-Certificate"><span class="toc-nav-number">3.2.1.</span> <span class="toc-nav-text">API Server Certificate</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#Front-Proxy-Certificate"><span class="toc-nav-number">3.2.2.</span> <span class="toc-nav-text">Front Proxy Certificate</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#Admin-Certificate"><span class="toc-nav-number">3.2.3.</span> <span class="toc-nav-text">Admin Certificate</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#Controller-Manager-Certificate"><span class="toc-nav-number">3.2.4.</span> <span class="toc-nav-text">Controller Manager Certificate</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#Scheduler-Certificate"><span class="toc-nav-number">3.2.5.</span> <span class="toc-nav-text">Scheduler Certificate</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#Master-Kubelet-Certificate"><span class="toc-nav-number">3.2.6.</span> <span class="toc-nav-text">Master Kubelet Certificate</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#Service-Account-Key"><span class="toc-nav-number">3.2.7.</span> <span class="toc-nav-text">Service Account Key</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#刪除不必要檔案"><span class="toc-nav-number">3.2.8.</span> <span class="toc-nav-text">刪除不必要檔案</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#複製檔案至其他節點"><span class="toc-nav-number">3.2.9.</span> <span class="toc-nav-text">複製檔案至其他節點</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Kubernetes-Masters"><span class="toc-nav-number">4.</span> <span class="toc-nav-text">Kubernetes Masters</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#部署與設定"><span class="toc-nav-number">4.1.</span> <span class="toc-nav-text">部署與設定</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#驗證叢集"><span class="toc-nav-number">4.2.</span> <span class="toc-nav-text">驗證叢集</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#建立-TLS-Bootstrapping-RBAC-與-Secret"><span class="toc-nav-number">4.3.</span> <span class="toc-nav-text">建立 TLS Bootstrapping RBAC 與 Secret</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Kubernetes-Nodes"><span class="toc-nav-number">5.</span> <span class="toc-nav-text">Kubernetes Nodes</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#部署與設定-1"><span class="toc-nav-number">5.1.</span> <span class="toc-nav-text">部署與設定</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#驗證叢集-1"><span class="toc-nav-number">5.2.</span> <span class="toc-nav-text">驗證叢集</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Kubernetes-Core-Addons-部署"><span class="toc-nav-number">6.</span> <span class="toc-nav-text">Kubernetes Core Addons 部署</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Kubernetes-Proxy"><span class="toc-nav-number">6.1.</span> <span class="toc-nav-text">Kubernetes Proxy</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Kubernetes-DNS"><span class="toc-nav-number">6.2.</span> <span class="toc-nav-text">Kubernetes DNS</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Calico-Network-安裝與設定"><span class="toc-nav-number">7.</span> <span class="toc-nav-text">Calico Network 安裝與設定</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Kubernetes-Extra-Addons-部署"><span class="toc-nav-number">8.</span> <span class="toc-nav-text">Kubernetes Extra Addons 部署</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Dashboard"><span class="toc-nav-number">8.1.</span> <span class="toc-nav-text">Dashboard</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Heapster"><span class="toc-nav-number">8.2.</span> <span class="toc-nav-text">Heapster</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Ingress-Controller"><span class="toc-nav-number">8.3.</span> <span class="toc-nav-text">Ingress Controller</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#測試-Ingress-功能"><span class="toc-nav-number">8.3.1.</span> <span class="toc-nav-text">測試 Ingress 功能</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Helm-Tiller-Server"><span class="toc-nav-number">8.4.</span> <span class="toc-nav-text">Helm Tiller Server</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#測試-Helm-功能"><span class="toc-nav-number">8.4.1.</span> <span class="toc-nav-text">測試 Helm 功能</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#測試叢集"><span class="toc-nav-number">9.</span> <span class="toc-nav-text">測試叢集</span></a></li></ol>
        
        </div>
      </aside>
    

                
            <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                       
                          <a class="tag" href="/tags/#Docker" title="Docker">Docker</a>
                        
                          <a class="tag" href="/tags/#Kubernetes" title="Kubernetes">Kubernetes</a>
                        
                          <a class="tag" href="/tags/#Calico" title="Calico">Calico</a>
                        
                    </div>
                </section>
                

                <!-- Friends Blog -->
                
                <hr>
                <h5>FRIENDS</h5>
                <ul class="list-inline">

                    
                        <li><a href="https://hwchiu.com" target="_blank">威猛邱牛的部落格</a></li>
                    
                        <li><a href="http://www.evanlin.com" target="_blank">吃草爸爸的部落格</a></li>
                    
                        <li><a href="https://ellis-wu.github.io" target="_blank">跟我一樣可悲的同事部落格</a></li>
                    
                        <li><a href="https://blog.pichuang.com.tw" target="_blank">小飛機的部落格</a></li>
                    
                        <li><a href="https://bestsamina.github.io/" target="_blank">超猛姍蓉的部落格</a></li>
                    
                        <li><a href="https://igene.tw" target="_blank">郭大俠的部落格</a></li>
                    
                </ul>
                
            </div>
        </div>
    </div>
</article>




<!-- disqus embedded js code start (one page only need to embed once) -->
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = "shenhengheng";
    var disqus_identifier = "https://readailib.github.io/2018/04/05/kubernetes/deploy/manual-v1.10/";
    var disqus_url = "https://readailib.github.io/2018/04/05/kubernetes/deploy/manual-v1.10/";

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<!-- disqus embedded js code start end -->




<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'left',
          icon: 'ℬ'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                
                    <li>
                        <a href="/atom.xml">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                
                
                    <li>
                        <a target="_blank" href="https://twitter.com/shenhengheng">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                
                

                

                
                    <li>
                        <a target="_blank" href="https://www.facebook.com/shenhengheng">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="https://github.com/rh01">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="https://www.linkedin.com/in/heng960509">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; ShenHengheng 2019
                    <br>
                    Theme by <a href="http://huangxuan.me">Hux</a>
                    <span style="display: inline-block; margin: 0 5px;">
                        <i class="fa fa-heart"></i>
                    </span>
                    re-Ported by <a href="http://beantech.org">BeanTech</a> |
                    <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://ghbtns.com/github-btn.html?user=YenYuHsuan&repo=hexo-theme-beantech&type=star&count=true">
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://readailib.github.io/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->




<!-- Baidu Tongji -->



<!-- Highlight.js -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-dark.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>




	<a id="rocket" href="#top" class=""></a>
	<script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
    <script type="text/javascript" src="/js/toc.js?v=1.0.0" async=""></script>
<!-- Image to hack wechat -->
<img src="https://readailib.github.io/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
